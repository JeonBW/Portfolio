{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시퀀스 데이터(순차적으로 이루어진 데이터 / 대부분 문자로 이루어진 데이터/ 주로 문장들을 이해하는데 도움)\n",
    "- 가장 활발하게 이용하는 부분이 챗봇 \n",
    "- time series \n",
    "- POS tagging : 품사를 구분하기 위한 목적으로 사용\n",
    "- BPTT 백프로포게이션을 시간에따라서 거슬러 올라가는 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단일 cell 을 통한 계산 처리 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 준비\n",
    "inputs = np.array([[[1, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 3), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      "\n",
      " \\eights\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(7, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action =\"ignore\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "tf_inputs = tf.constant(inputs, dtype = tf.float32)\n",
    "\n",
    "# RNN cell 만들기 (cell을 만들고 -> 어떻게 가동시킬지 설정)\n",
    "# 1* 3의 matrix 출력([6, 7, 8]과 같은)\n",
    "rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=3) # 네모박스를 하나 만든 것\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=rnn_cell, dtype=tf.float32, inputs= tf_inputs) \n",
    "# 네모박스를 실행 / 출력이 2번실행되기 때문에 2번 받을 수 있다. \n",
    "print(outputs)\n",
    "print(state)\n",
    "print(\"\\n\\n \\eights\")# 가중치 값\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "    print(w)\n",
    "# 5행 3열인 이유 : Wxh 2행3열 과 Whh 3행3열 -> 5행3열 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Value\n",
      "[[[-0.9314169   0.75578666 -0.6819246 ]]]\n",
      "State Value\n",
      "[[-0.9314169   0.75578666 -0.6819246 ]]\n",
      "rnn/basic_rnn_cell/kernel:0 [[-0.62831575  0.38538355  0.79733914]\n",
      " [-0.5203329   0.30046564 -0.8150209 ]\n",
      " [ 0.39399797  0.16670114  0.4062907 ]\n",
      " [-0.6391754   0.8460203   0.5266966 ]\n",
      " [ 0.41124135  0.66347724 -0.0210759 ]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    " with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        output_run, state_run = sess.run([outputs, state])\n",
    "        print(\"Output Value\")\n",
    "        print(output_run)\n",
    "        print(\"State Value\")\n",
    "        print(state_run)\n",
    "        \n",
    "        # output과 state의 값이 똑같다.\n",
    "        \n",
    "        variables_names = [v.name for v in tf.trainable_variables()]\n",
    "        #print(variables_names) #하나는 가중치 하나는 바이어스\n",
    "        values = sess.run(variables_names)\n",
    "        for k, v in zip(variables_names, values):\n",
    "            print(k, v) # 5행 3열짜리 가중치와 바이어스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 0]\n",
      "  [0 1 0 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 0 1]]\n",
      "\n",
      " [[1 0 0 0]\n",
      "  [0 0 0 1]\n",
      "  [0 0 1 0]\n",
      "  [0 1 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# i work at google  ->  i = [[1, 0, 0, 0]] , work =[[0, 1, 0, 0]], at = [[0, 0, 1, 0]], google = [[0, 0, 0, 1]]\n",
    "# i google at work ->    i = [[1, 0, 0, 0]] , google =[[0, 0, 0, 1]], at = [[0, 0, 1, 0]], work = [[0, 1, 0, 0]]\n",
    "\n",
    "inputs = np.array([[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], # 입력데이터 1행 4열짜리가 순차적으로 들어가는  \n",
    "                 [[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0]]]) \n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(2, 4, 3), dtype=float32)\n",
      "--------------------------------\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(2, 3), dtype=float32)\n",
      "--------------------------------\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(7, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "tf_inputs = tf.constant(inputs, dtype = tf.float32)\n",
    "\n",
    "# cell 모델링\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(num_units = 3) # num_units 지정은 자유 -> 출력갯수 \n",
    "outputs, state = tf.nn.dynamic_rnn(cell=rnn_cell, dtype = tf.float32, inputs = tf_inputs)\n",
    "variables_names = [v.name for v in tf.trainable_variables()]\n",
    "print(outputs) # 입력값개수, /입력되는 열의 갯수 / 출력 갯수 \n",
    "print(\"--------------------------------\")\n",
    "print(state) # 여러 cell을 지나서 최종적으로 출력된 state : 전체 입력갯수 2문장, / 출력갯수\n",
    "print(\"--------------------------------\")\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES): #\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Value\n",
      "[[[-0.50944704  0.33166462  0.6126557 ]\n",
      "  [-0.20793891  0.24406303 -0.75278705]\n",
      "  [-0.06346128 -0.52844936  0.68356085]\n",
      "  [-0.36491966  0.8857268  -0.02324395]]\n",
      "\n",
      " [[-0.50944704  0.33166462  0.6126557 ]\n",
      "  [-0.30707452  0.62735885  0.21719742]\n",
      "  [ 0.5043804  -0.14038289  0.3744523 ]\n",
      "  [-0.11641277  0.70696247 -0.7512605 ]]]\n",
      "State Value\n",
      "[[-0.36491966  0.8857268  -0.02324395]\n",
      " [-0.11641277  0.70696247 -0.7512605 ]]\n",
      "rnn/basic_rnn_cell/kernel:0 [[-0.56198275  0.34469748  0.7131618 ]\n",
      " [-0.4653999   0.2687447  -0.7289769 ]\n",
      " [ 0.35240245  0.14910203  0.36339748]\n",
      " [-0.57169586  0.7567036   0.47109187]\n",
      " [ 0.3678255   0.5934322  -0.01885086]\n",
      " [ 0.31208777 -0.40880746  0.22867584]\n",
      " [ 0.5521256   0.682691   -0.5481483 ]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    " with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        output_run, state_run = sess.run([outputs, state])\n",
    "        print(\"Output Value\") # 단어가 4개이기 때문에 4개나옴 / 두개의 문장을 출력한것/ 열은 내가 임의로 지정한 것 n_units \n",
    "        # 4행 4열짜리가 4행 3열 되기위해서는 *4행 3열이 되야한다.\n",
    "        # 처음 값은 똑같으나 가중치 계산이 되면서 계속 달라진다. \n",
    "        # 같은 단어여서 무조건 처음이 같은게 아니라 이전으로부터 입력받은 값 없이 순수한결과값이기 때문에 같은 건이다 (i 와 at 의 차이)\n",
    "        print(output_run)\n",
    "        print(\"State Value\")\n",
    "        # 처음 시작은 4행 3열로 시작하지만 마지막에는 2행 3열이 된다. \n",
    "        # 2행 3열이 3행 3열이 되기위해서는 *3형 3열이 되야한다.\n",
    "        # 그래서 output의 최종결과값 하고 state는 값은 값이 출력된다.\n",
    "        # 따라서 가중치는 4행 3열과 3행 3열의 합 7행 3열이 된다.\n",
    "        print(state_run)\n",
    "        \n",
    "        # output과 state의 값이 똑같다.\n",
    "        \n",
    "        #print(variables_names) #하나는 가중치 하나는 바이어스\n",
    "        values = sess.run(variables_names)\n",
    "        for k, v in zip(variables_names, values):\n",
    "            print(k, v) # 5행 3열짜리 가중치와 바이어스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[[1, 0, 0, 0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 3), dtype=float32)\n",
      "--------------------------------\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(1, 3), dtype=float32)\n",
      "--------------------------------\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(7, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "tf_inputs = tf.constant(inputs, dtype = tf.float32)\n",
    "\n",
    "# cell 모델링\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(num_units = 3) # num_units 지정은 자유 -> 출력갯수 \n",
    "outputs, state = tf.nn.dynamic_rnn(cell=rnn_cell, dtype = tf.float32, inputs = tf_inputs)\n",
    "variables_names = [v.name for v in tf.trainable_variables()]\n",
    "print(outputs) # 입력값개수, /입력될떄 열의 갯수 / 출력 갯수 \n",
    "print(\"--------------------------------\")\n",
    "print(state) # 여러 cell을 지나서 최종적으로 출력된 state : 전체 입력갯수 2문장, / 출력갯수\n",
    "print(\"--------------------------------\")\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES): #\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Value\n",
      "[[[-0.50944704  0.33166462  0.6126557 ]]]\n",
      "State Value\n",
      "[[-0.50944704  0.33166462  0.6126557 ]]\n",
      "rnn/basic_rnn_cell/kernel:0 [[-0.56198275  0.34469748  0.7131618 ]\n",
      " [-0.4653999   0.2687447  -0.7289769 ]\n",
      " [ 0.35240245  0.14910203  0.36339748]\n",
      " [-0.57169586  0.7567036   0.47109187]\n",
      " [ 0.3678255   0.5934322  -0.01885086]\n",
      " [ 0.31208777 -0.40880746  0.22867584]\n",
      " [ 0.5521256   0.682691   -0.5481483 ]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    " with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        output_run, state_run = sess.run([outputs, state])\n",
    "        print(\"Output Value\") # 단어가 4개이기 때문에 4개나옴 / 두개의 문장을 출력한것/ 열은 내가 임의로 지정한 것 n_units \n",
    "        # 4행 4열짜리가 4행 3열 되기위해서는 *4행 3열이 되야한다.\n",
    "        # 처음 값은 똑같으나 가중치 계산이 되면서 계속 달라진다. \n",
    "        # 같은 단어여서 무조건 처음이 같은게 아니라 이전으로부터 입력받은 값 없이 순수한결과값이기 때문에 같은 건이다 (i 와 at 의 차이)\n",
    "        print(output_run)\n",
    "        print(\"State Value\")\n",
    "        # 처음 시작은 4행 3열로 시작하지만 마지막에는 2행 3열이 된다. \n",
    "        # 2행 3열이 3행 3열이 되기위해서는 *3형 3열이 되야한다.\n",
    "        # 그래서 output의 최종결과값 하고 state는 값은 값이 출력된다.\n",
    "        # 따라서 가중치는 4행 3열과 3행 3열의 합 7행 3열이 된다.\n",
    "        print(state_run)\n",
    "        \n",
    "        # output과 state의 값이 똑같다.\n",
    "        \n",
    "        #print(variables_names) #하나는 가중치 하나는 바이어스\n",
    "        values = sess.run(variables_names)\n",
    "        for k, v in zip(variables_names, values):\n",
    "            print(k, v) # 5행 3열짜리 가중치와 바이어스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 5, 3), dtype=float32)\n",
      "--------------------------------\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(1, 3), dtype=float32)\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(7, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n",
      "Output Value\n",
      "[[[ 0.34300327 -0.107384   -0.46925384]\n",
      "  [-0.2774119  -0.5878217   0.09722161]\n",
      "  [ 0.75449204  0.33791998 -0.33005482]\n",
      "  [-0.34582028 -0.25192338  0.33335426]\n",
      "  [ 0.5475094  -0.22006126 -0.02506072]]]\n",
      "State Value\n",
      "[[ 0.5475094  -0.22006126 -0.02506072]]\n",
      "rnn/basic_rnn_cell/kernel:0 [[ 0.35749233 -0.10779965 -0.5091131 ]\n",
      " [ 0.14107978 -0.518346    0.12631565]\n",
      " [ 0.41646826 -0.04292756 -0.00733286]\n",
      " [ 0.05838621 -0.5328102   0.13483173]\n",
      " [-0.41033363  0.37693584  0.38223803]\n",
      " [-0.6456835  -0.72144556  0.4305197 ]\n",
      " [ 0.7555529   0.7730297   0.24222267]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n",
    "\n",
    "x_data = np.array([[h, e, l, l, o ]], dtype = np.float32)\n",
    "\n",
    "\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(num_units = 3)\n",
    "\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=rnn_cell, dtype = tf.float32, inputs = x_data)\n",
    "\n",
    "variables_names = [v.name for v in tf.trainable_variables()]\n",
    "print(outputs) # 입력값개수, /입력될떄 열의 갯수 / 출력 갯수 \n",
    "print(\"--------------------------------\")\n",
    "print(state) # 여러 cell을 지나서 최종적으로 출력된 state : 전체 입력갯수 2문장, / 출력갯수\n",
    "print(\"--------------------------------\")\n",
    "print(\"--------------------------------\")\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES): #\n",
    "    print(w)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        output_run, state_run = sess.run([outputs, state])\n",
    "        print(\"Output Value\") \n",
    "        print(output_run)\n",
    "        print(\"State Value\")\n",
    "        print(state_run)\n",
    "\n",
    "        values = sess.run(variables_names)\n",
    "        for k, v in zip(variables_names, values):\n",
    "            print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sequence_length : 입력데이터의 갯수 = 셀의 갯수\n",
    "- hidden_size = 출력의 갯수 \n",
    "- batch_size = 데이터의 갯수(훈련횟수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hihello 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e','l','o']\n",
    "x_one_hot = [[[1, 0, 0, 0, 0],\n",
    "             [0, 1, 0, 0, 0],\n",
    "             [1, 0, 0, 0, 0],\n",
    "             [0, 0, 1, 0, 0],\n",
    "             [0, 0, 0, 1, 0],\n",
    "             [0, 0, 0, 1, 0],\n",
    "             [0, 0, 0, 0, 1]]]\n",
    "#x_data = [[0, 1, 0, 2, 3, 3]] # h는0, i는1, e는 2..... -> hihell\n",
    "y_data = [[0, 1, 0, 2, 3, 3, 4]] # ihello 출력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "sequence_len = 7\n",
    "num_classes = 5\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# X, y 준비 (입출력 데이터 준비 )\n",
    "X = tf.placeholder(tf.float32, shape=[None, sequence_len, num_classes])  # 입력데이터는 3차원 (이미지만 4차원)/ 전체 데이터의 갯수, 입력되는 열의 갯수, 출력갯수\n",
    "# 실제로는 출력갯수는 출력할 수 있는 갯수\n",
    "y = tf.placeholder(tf.int32, shape=[None, sequence_len])  # y 값은 정수형으로 (원핫 인코딩했기 때문에)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 5), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# rnn 모델\n",
    "cell  = tf.contrib.rnn.BasicRNNCell(num_units = num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell = cell, inputs = X, dtype = tf.float32)\n",
    "\n",
    "print(outputs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 평면화 (Flat Layer)\n",
    "X_for_fc = tf.reshape(outputs, [-1, num_classes])\n",
    "print(X_for_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 1.4880387       prediction: [[3 3 3 3 3 3]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "1 cost : 1.3550959       prediction: [[3 3 3 3 3 3]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "2 cost : 1.2024946       prediction: [[1 0 3 3 4 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "3 cost : 1.010539       prediction: [[1 1 2 3 4 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "4 cost : 0.8755426       prediction: [[1 1 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "5 cost : 0.7909606       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "6 cost : 0.6636115       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "7 cost : 0.54720175       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "8 cost : 0.47552872       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "9 cost : 0.41703203       prediction: [[1 0 2 3 3 3]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "10 cost : 0.35898462       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "11 cost : 0.29545656       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "12 cost : 0.22868524       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "13 cost : 0.17776442       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "14 cost : 0.13943373       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "15 cost : 0.101136774       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "16 cost : 0.071107276       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "17 cost : 0.056756184       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "18 cost : 0.045174453       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "19 cost : 0.035811286       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "20 cost : 0.031216996       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "21 cost : 0.027534535       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "22 cost : 0.023875648       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "23 cost : 0.020584902       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "24 cost : 0.017814828       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "25 cost : 0.015393882       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "26 cost : 0.013130703       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "27 cost : 0.011041003       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "28 cost : 0.009258255       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "29 cost : 0.007850624       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "30 cost : 0.0067772516       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "31 cost : 0.0059526614       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "32 cost : 0.005301164       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "33 cost : 0.0047707297       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "34 cost : 0.00432834       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "35 cost : 0.003952806       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "36 cost : 0.00363015       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "37 cost : 0.00335054       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "38 cost : 0.0031069163       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "39 cost : 0.002893672       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "40 cost : 0.0027065577       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "41 cost : 0.0025419916       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "42 cost : 0.0023970788       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "43 cost : 0.0022689996       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "44 cost : 0.0021558444       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "45 cost : 0.0020555805       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "46 cost : 0.0019665698       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "47 cost : 0.0018874112       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "48 cost : 0.0018167015       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "49 cost : 0.0017534732       prediction: [[1 0 2 3 3 4]]     정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "결과 : i,h,e,l,l,o\n"
     ]
    }
   ],
   "source": [
    "# FC (W, b, logit)\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(inputs=X_for_fc, num_outputs=num_classes, activation_fn=None) # 입력데이터, 출력의 갯수\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_len, num_classes]) # 전체 데이터의 갯수, 데이터의 길이, 출력의 갯수\n",
    "W = tf.ones([batch_size, sequence_len])\n",
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=y , weights=W)) # logits는 3차원으로\n",
    "# 시퀀스 데이터이기 때문에 순서가 중요하다 / 일반적인 비용구하는 공식으로 하면 안된다.\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        _, c = sess.run([train,cost], feed_dict={X:x_one_hot, y:y_data})\n",
    "        result = sess.run(tf.argmax(outputs,2), feed_dict={X:x_one_hot})\n",
    "        print(i, \"cost :\", c, \"      prediction:\", result, \"    정답 :\", y_data)\n",
    "    result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "    print(\"결과 :\", \",\".join(result_str) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 1.7951401       prediction: [[3 4 3 4 3 3 0]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "1 cost : 1.3937826       prediction: [[0 1 0 4 3 3 0]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "2 cost : 1.1056939       prediction: [[0 1 0 1 3 3 0]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "3 cost : 0.8646723       prediction: [[0 1 0 1 3 3 0]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "4 cost : 0.69971305       prediction: [[0 1 0 1 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "5 cost : 0.54325426       prediction: [[0 1 0 1 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "6 cost : 0.42672417       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "7 cost : 0.34361717       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "8 cost : 0.2767791       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "9 cost : 0.2180494       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "10 cost : 0.16740768       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "11 cost : 0.12690246       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "12 cost : 0.0962582       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "13 cost : 0.0728913       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "14 cost : 0.054598324       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "15 cost : 0.04050046       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "16 cost : 0.03009617       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "17 cost : 0.022667361       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "18 cost : 0.017415937       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "19 cost : 0.013678064       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "20 cost : 0.010975399       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "21 cost : 0.008982743       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "22 cost : 0.00748305       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "23 cost : 0.0063316477       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "24 cost : 0.0054315925       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "25 cost : 0.0047168327       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "26 cost : 0.0041413796       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "27 cost : 0.0036726866       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "28 cost : 0.0032869503       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "29 cost : 0.0029666738       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "30 cost : 0.0026984992       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "31 cost : 0.002472305       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "32 cost : 0.0022801307       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "33 cost : 0.0021158492       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "34 cost : 0.001974509       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "35 cost : 0.001852154       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "36 cost : 0.0017457388       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "37 cost : 0.0016526902       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "38 cost : 0.001570908       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "39 cost : 0.0014986977       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "40 cost : 0.0014346865       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "41 cost : 0.0013776871       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "42 cost : 0.0013266992       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "43 cost : 0.0012809762       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "44 cost : 0.0012398736       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "45 cost : 0.0012026612       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "46 cost : 0.0011688633       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "47 cost : 0.0011382943       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "48 cost : 0.001110291       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "49 cost : 0.0010846668       prediction: [[0 1 0 2 3 3 4]]     정답 : [[0, 1, 0, 2, 3, 3, 4]]\n",
      "결과 : h,i,h,e,l,l,o\n"
     ]
    }
   ],
   "source": [
    "# FC (W, b, logit)\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(inputs=X_for_fc, num_outputs=num_classes, activation_fn=None) # 입력데이터, 출력의 갯수\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_len, num_classes]) # 전체 데이터의 갯수, 데이터의 길이, 출력의 갯수\n",
    "W = tf.ones([batch_size, sequence_len])\n",
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=y , weights=W)) # logits는 3차원으로\n",
    "# 시퀀스 데이터이기 때문에 순서가 중요하다 / 일반적인 비용구하는 공식으로 하면 안된다.\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        _, c = sess.run([train,cost], feed_dict={X:x_one_hot, y:y_data})\n",
    "        result = sess.run(tf.argmax(outputs,2), feed_dict={X:x_one_hot})\n",
    "        print(i, \"cost :\", c, \"      prediction:\", result, \"    정답 :\", y_data)\n",
    "    result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "    print(\"결과 :\", \",\".join(result_str) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 두 번째 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'n', 'o', 'w', 'f', ' ', 'u', 'y', 'a', 'i']\n",
      "{'t': 0, 'n': 1, 'o': 2, 'w': 3, 'f': 4, ' ': 5, 'u': 6, 'y': 7, 'a': 8, 'i': 9}\n",
      "[5, 9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "sample = \" if you want you\"\n",
    "idx2char = list(set(sample))\n",
    "print(idx2char)\n",
    "\n",
    "char2idx = {c:i for i, c in enumerate(idx2char)}\n",
    "print(char2idx)\n",
    "\n",
    "sample_idx = [char2idx[c] for c in sample]\n",
    "print(sample_idx)\n",
    "\n",
    "x_data = [sample_idx[:-1]]\n",
    "y_data = [sample_idx[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "num_classes = len(char2idx)\n",
    "batch_szie = 1\n",
    "sequence_len = len(sample) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 15, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, shape=[None, sequence_len])  # one-hot인코딩을 사용할 것이기 때문에 2차원으로\n",
    "y = tf.placeholder(tf.int32, shape=[None, sequence_len]) \n",
    "\n",
    "x_one_hot = tf.one_hot(X, num_classes)\n",
    "print(x_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell  = tf.contrib.rnn.BasicRNNCell(num_units = num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell = cell, inputs = x_one_hot, dtype = tf.float32)\n",
    "\n",
    "W = tf.ones([batch_size, sequence_len])\n",
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=y , wetights=W)) \n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 2.2372687       prediction: [[6 1 5 6 2 6 5 9 5 1 5 6 5 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : u,n, ,u,o,u, ,i, ,n, ,u, ,o,u\n",
      "1 cost : 1.8941674       prediction: [[9 1 5 6 2 6 5 9 5 1 0 5 6 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,n, ,u,o,u, ,i, ,n,t, ,u,o,u\n",
      "2 cost : 1.7404529       prediction: [[9 1 5 7 2 6 5 6 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,n, ,y,o,u, ,u,a,n,t, ,y,o,u\n",
      "3 cost : 1.5966445       prediction: [[9 1 5 7 5 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,n, ,y, ,u, ,w,a,n,t, ,y,o,u\n",
      "4 cost : 1.4902977       prediction: [[9 1 5 7 5 6 5 3 8 1 0 5 7 5 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,n, ,y, ,u, ,w,a,n,t, ,y, ,u\n",
      "5 cost : 1.4123538       prediction: [[9 1 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,n, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "6 cost : 1.3259403       prediction: [[9 4 5 7 2 6 5 3 8 7 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,y,t, ,y,o,u\n",
      "7 cost : 1.2671722       prediction: [[9 4 5 7 2 6 5 3 8 7 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,y,t, ,y,o,u\n",
      "8 cost : 1.2012575       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "9 cost : 1.1592256       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "10 cost : 1.1118355       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "11 cost : 1.074646       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "12 cost : 1.0411627       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "13 cost : 1.008573       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "14 cost : 0.98689896       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "15 cost : 0.96841305       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "16 cost : 0.9521578       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "17 cost : 0.9385728       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "18 cost : 0.92840487       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "19 cost : 0.9198282       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "20 cost : 0.9109036       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "21 cost : 0.9017076       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "22 cost : 0.8928201       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "23 cost : 0.8846872       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "24 cost : 0.8780109       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "25 cost : 0.87277997       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "26 cost : 0.8673062       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "27 cost : 0.86235213       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "28 cost : 0.8587731       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "29 cost : 0.8556562       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "30 cost : 0.8523794       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "31 cost : 0.8491766       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "32 cost : 0.84651667       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "33 cost : 0.8441685       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "34 cost : 0.84156024       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "35 cost : 0.83909684       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "36 cost : 0.8372007       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "37 cost : 0.83557564       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "38 cost : 0.83389175       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "39 cost : 0.83216566       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "40 cost : 0.83068544       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "41 cost : 0.829616       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "42 cost : 0.82861334       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "43 cost : 0.8274342       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "44 cost : 0.8264137       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "45 cost : 0.82565284       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "46 cost : 0.8249111       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "47 cost : 0.824089       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "48 cost : 0.82334775       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "49 cost : 0.8228119       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "50 cost : 0.8222641       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "51 cost : 0.8216221       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 cost : 0.8211108       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "53 cost : 0.82070047       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "54 cost : 0.82024676       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "55 cost : 0.8197781       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "56 cost : 0.81940866       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "57 cost : 0.8190851       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "58 cost : 0.8187026       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "59 cost : 0.8183538       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "60 cost : 0.8180767       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "61 cost : 0.81778854       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "62 cost : 0.8174806       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "63 cost : 0.81721866       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "64 cost : 0.8169862       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "65 cost : 0.8167234       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "66 cost : 0.8164768       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "67 cost : 0.8162683       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "68 cost : 0.8160516       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "69 cost : 0.81582856       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "70 cost : 0.8156357       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "71 cost : 0.8154513       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "72 cost : 0.81525326       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "73 cost : 0.8150737       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "74 cost : 0.8149086       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "75 cost : 0.814735       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "76 cost : 0.8145685       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "77 cost : 0.81441855       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "78 cost : 0.81426305       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "79 cost : 0.81410956       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "80 cost : 0.81396955       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "81 cost : 0.81382805       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "82 cost : 0.8136864       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "83 cost : 0.8135556       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "84 cost : 0.81342584       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "85 cost : 0.81329507       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "86 cost : 0.8131726       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "87 cost : 0.81305176       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "88 cost : 0.81293017       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "89 cost : 0.81281495       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "90 cost : 0.812702       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "91 cost : 0.8125886       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "92 cost : 0.8124802       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "93 cost : 0.81237376       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "94 cost : 0.8122673       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "95 cost : 0.8121649       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "96 cost : 0.8120641       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "97 cost : 0.81196374       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "98 cost : 0.8118669       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n",
      "99 cost : 0.81177133       prediction: [[9 4 5 7 2 6 5 3 8 1 0 5 7 2 6]]     정답 : [[9, 4, 5, 7, 2, 6, 5, 3, 8, 1, 0, 5, 7, 2, 6]]\n",
      "결과 : i,f, ,y,o,u, ,w,a,n,t, ,y,o,u\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        _, c = sess.run([train,cost], feed_dict={X:x_data, y:y_data})\n",
    "        result = sess.run(tf.argmax(outputs,2), feed_dict={X:x_data})\n",
    "        print(i, \"cost :\", c, \"      prediction:\", result, \"    정답 :\", y_data)\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"결과 :\", \",\".join(result_str) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Shore Term Memory)\n",
    "\n",
    "+ BackPropagation Through Time(BPTT)\n",
    "    - Gradient Vanishing\n",
    "    - Gradient Exploding\n",
    "    \n",
    "- memory cell : 새로운 출력이 하나 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.09927537]]]\n",
      "[[0.09927537]]\n",
      "[[0.18134572]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "inputs = np.array([[[1, 0]]])\n",
    "tf_inputs = tf.constant(inputs, dtype=tf.float32)\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units = 1)\n",
    "outputs ,states = tf.nn.dynamic_rnn(cell=cell, dtype = tf.float32, inputs=tf_inputs) \n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_run, states_run = sess.run([outputs, states])\n",
    "    print(outputs_run)\n",
    "    print(states_run.h) # 히든 states 값\n",
    "    # 처음이기 때문에 출력값과 states값이 같다. \n",
    "    print(states_run.c) #c는 메모리 cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic_rnn이란?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the garlic fries were a great starter (and a h...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>our meal was excellent i had the pasta ai form...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what i enjoy most about palo alto is so many r...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the drinks came out fairly quickly a good two ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>despite the not so good burger the service was...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the four reigning major champions simona halep...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the briton was seeded nn7 here last year befor...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stephens surged her way back from injury in st...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>when it came to england chances in the world c...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the team that eliminated russia – croatia – al...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the perseyside outfit finished in fourth place...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>liverpool fc will return to premier league act...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alisson signed for liverpool fc from as roma t...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>but the rankings during that run-in to new yor...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>then came the oh-so-familiar djokovic-nadal no...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paragraph category\n",
       "0   dishplace is located in sunnyvale downtown the...     food\n",
       "1   service can be slower during busy hours but ou...     food\n",
       "2   portions are huge both french toast and their ...     food\n",
       "3   we started with apps going the chicken and waf...     food\n",
       "4   the biscuits and gravy was too salty two peopl...     food\n",
       "5   the garlic fries were a great starter (and a h...     food\n",
       "6   our meal was excellent i had the pasta ai form...     food\n",
       "7   what i enjoy most about palo alto is so many r...     food\n",
       "8   the drinks came out fairly quickly a good two ...     food\n",
       "9   despite the not so good burger the service was...     food\n",
       "10  the four reigning major champions simona halep...   sports\n",
       "11  the briton was seeded nn7 here last year befor...   sports\n",
       "12  stephens surged her way back from injury in st...   sports\n",
       "13  when it came to england chances in the world c...   sports\n",
       "14  the team that eliminated russia – croatia – al...   sports\n",
       "15  the perseyside outfit finished in fourth place...   sports\n",
       "16  liverpool fc will return to premier league act...   sports\n",
       "17  alisson signed for liverpool fc from as roma t...   sports\n",
       "18  but the rankings during that run-in to new yor...   sports\n",
       "19  then came the oh-so-familiar djokovic-nadal no...   sports"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dict_list = [\n",
    "         {'paragraph': 'dishplace is located in sunnyvale downtown there is parking around the area but it can be difficult to find during peak business hours my sisters and i came to this place for dinner on a weekday they were really busy so i highly recommended making reservations unless you have the patience to wait', 'category': 'food'},\n",
    "         {'paragraph': 'service can be slower during busy hours but our waiter was courteous and help gave some great entree recommendations', 'category': 'food'},\n",
    "         {'paragraph': 'portions are huge both french toast and their various omelettes are really good their french toast is probably 1.5x more than other brunch places great place to visit if you are hungry and dont want to wait 1 hour for a table', 'category': 'food'},\n",
    "         {'paragraph': 'we started with apps going the chicken and waffle slides and chicken nachos the sliders were amazing and the nachos were good too maybe by themselves the nachos would have scored better but after those sliders they were up against some tough competition', 'category': 'food'},\n",
    "         {'paragraph': 'the biscuits and gravy was too salty two people in my group had the gravy and all thought it was too salty my hubby ordered a side of double egg and it was served on two small plates who serves eggs to one person on separate plates we commented on that when it was delivered and even the server laughed and said she doesnt know why the kitchen does that presentation of food is important and they really missed on this one', 'category': 'food'},\n",
    "         {'paragraph': 'the garlic fries were a great starter (and a happy hour special) the pancakes looked and tasted great and were a fairly generous portion', 'category': 'food'},\n",
    "         {'paragraph': 'our meal was excellent i had the pasta ai formaggi which was so rich i didnt dare eat it all although i certainly wanted to excellent flavors with a great texture contrast between the soft pasta and the crisp bread crumbs too much sauce for me but a wonderful dish', 'category': 'food'},\n",
    "         {'paragraph': 'what i enjoy most about palo alto is so many restaurants have dog-friendly seating outside i had bookmarked italico from when they first opened about a 1.5 years ago and was jonesing for some pasta so time to finally knock that bookmark off', 'category': 'food'},\n",
    "         {'paragraph': 'the drinks came out fairly quickly a good two to three minutes after the orders were taken i expected my iced tea to taste a bit more sweet but this was straight up green tea with ice in it not to complain of course but i was pleasantly surprised', 'category': 'food'},\n",
    "         {'paragraph': 'despite the not so good burger the service was so slow the restaurant wasnt even half full and they took very long from the moment we got seated to the time we left it was almost 2 hours we thought that it would be quick since we ordered as soon as we sat down my coworkers did seem to enjoy their beef burgers for those who eat beef however i will not be returning it is too expensive and extremely slow service', 'category': 'food'},\n",
    "    \n",
    "         {'paragraph': 'the four reigning major champions simona halep caroline wozniacki angelique kerber and defending us open champion sloane stephens could make a case for being the quartet most likely to succeed especially as all but stephens has also enjoyed the no1 ranking within the last 14 months as they prepare for their gruelling new york campaigns they currently hold the top four places in the ranks', 'category': 'sports'},\n",
    "         {'paragraph': 'the briton was seeded nn7 here last year before a slump in form and confidence took her down to no46 after five first-round losses but there have been signs of a turnaround including a victory over a sub-par serena williams in san jose plus wins against jelena ostapenko and victoria azarenka in montreal. konta pulled out of new haven this week with illness but will hope for good things where she first scored wins in a major before her big breakthroughs to the semis in australia and wimbledon', 'category': 'sports'},\n",
    "         {'paragraph': 'stephens surged her way back from injury in stunning style to win her first major here last year—and ranked just no83 she has since proved what a big time player she is winning the miami title via four fellow major champions then reaching the final at the french open back on north american hard courts she ran to the final in montreal only just edged out by halep she has also avoided many of the big names in her quarter—except for wild card azarenka as a possible in the third round', 'category': 'sports'},\n",
    "         {'paragraph': 'when it came to england chances in the world cup it would be fair to say that most fans had never been more pessimistic than they were this year after enduring years of truly dismal performances at major tournaments – culminating in the 2014 event where they failed to win any of their three group games and finished in bottom spot those results led to the resignation of manager roy hodgson', 'category': 'sports'},\n",
    "         {'paragraph': 'the team that eliminated russia – croatia – also improved enormously during the tournament before it began their odds were 33/1 but they played with real flair and star players like luka modric ivan rakitic and ivan perisic showed their quality on the world stage having displayed their potential by winning all three of their group stage games croatia went on to face difficult tests like the semi-final against england', 'category': 'sports'},\n",
    "         {'paragraph': 'the perseyside outfit finished in fourth place in the premier league table and without a trophy last term after having reached the champions league final before losing to real madrid', 'category': 'sports'},\n",
    "         {'paragraph': 'liverpool fc will return to premier league action on saturday lunchtime when they travel to leicester city in the top flight as they look to make it four wins in a row in the league', 'category': 'sports'},\n",
    "         {'paragraph': 'alisson signed for liverpool fc from as roma this summer and the brazilian goalkeeper has helped the reds to keep three clean sheets in their first three premier league games', 'category': 'sports'},\n",
    "         {'paragraph': 'but the rankings during that run-in to new york hid some very different undercurrents for murray had struggled with a hip injury since the clay swing and had not played a match since losing his quarter-final at wimbledon and he would pull out of the us open just two days before the tournament began—too late however to promote nederer to the no2 seeding', 'category': 'sports'},\n",
    "         {'paragraph': 'then came the oh-so-familiar djokovic-nadal no-quarter-given battle for dominance in the thiadal more than once pulled off a reverse smash and had his chance to seal the tie-break but it was djokovic serving at 10-9 who dragged one decisive error from nadal for a two-sets lead', 'category': 'sports'}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(paragraph_dict_list)\n",
    "df = df[[\"paragraph\", \"category\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing(데이터 전처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "Name: paragraph, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = set() #  set : 순서없이 중복된 데이터가 없이 저장하는 변수 \n",
    "df[\"paragraph\"].str.lower().str.split().apply(results.update) \n",
    "# 전부 소문자로 바꿔서 공백을 기준으로 단어를 뽑아낸 다음 results에 저장 (set 에 저장하기 위해서 update사용 / 리스트의 append와 같은)\n",
    "\n",
    "# 문장 분석을 위해서 단어들을 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(and',\n",
       " '1',\n",
       " '1.5',\n",
       " '1.5x',\n",
       " '10-9',\n",
       " '14',\n",
       " '2',\n",
       " '2014',\n",
       " '33/1',\n",
       " 'a',\n",
       " 'about',\n",
       " 'action',\n",
       " 'after',\n",
       " 'against',\n",
       " 'ago',\n",
       " 'ai',\n",
       " 'alisson',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'although',\n",
       " 'alto',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'and',\n",
       " 'angelique',\n",
       " 'any',\n",
       " 'apps',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'australia',\n",
       " 'avoided',\n",
       " 'azarenka',\n",
       " 'back',\n",
       " 'battle',\n",
       " 'be',\n",
       " 'beef',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'began—too',\n",
       " 'being',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'biscuits',\n",
       " 'bit',\n",
       " 'bookmark',\n",
       " 'bookmarked',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'brazilian',\n",
       " 'bread',\n",
       " 'breakthroughs',\n",
       " 'briton',\n",
       " 'brunch',\n",
       " 'burger',\n",
       " 'burgers',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'campaigns',\n",
       " 'can',\n",
       " 'card',\n",
       " 'caroline',\n",
       " 'case',\n",
       " 'certainly',\n",
       " 'champion',\n",
       " 'champions',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'chicken',\n",
       " 'city',\n",
       " 'clay',\n",
       " 'clean',\n",
       " 'commented',\n",
       " 'competition',\n",
       " 'complain',\n",
       " 'confidence',\n",
       " 'contrast',\n",
       " 'could',\n",
       " 'course',\n",
       " 'courteous',\n",
       " 'courts',\n",
       " 'coworkers',\n",
       " 'crisp',\n",
       " 'croatia',\n",
       " 'crumbs',\n",
       " 'culminating',\n",
       " 'cup',\n",
       " 'currently',\n",
       " 'dare',\n",
       " 'days',\n",
       " 'decisive',\n",
       " 'defending',\n",
       " 'delivered',\n",
       " 'despite',\n",
       " 'did',\n",
       " 'didnt',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'dish',\n",
       " 'dishplace',\n",
       " 'dismal',\n",
       " 'displayed',\n",
       " 'djokovic',\n",
       " 'djokovic-nadal',\n",
       " 'does',\n",
       " 'doesnt',\n",
       " 'dog-friendly',\n",
       " 'dominance',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'down',\n",
       " 'downtown',\n",
       " 'dragged',\n",
       " 'drinks',\n",
       " 'during',\n",
       " 'eat',\n",
       " 'edged',\n",
       " 'egg',\n",
       " 'eggs',\n",
       " 'eliminated',\n",
       " 'enduring',\n",
       " 'england',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enormously',\n",
       " 'entree',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'even',\n",
       " 'event',\n",
       " 'excellent',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'extremely',\n",
       " 'face',\n",
       " 'failed',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fans',\n",
       " 'fc',\n",
       " 'fellow',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finished',\n",
       " 'first',\n",
       " 'first-round',\n",
       " 'five',\n",
       " 'flair',\n",
       " 'flavors',\n",
       " 'flight',\n",
       " 'food',\n",
       " 'for',\n",
       " 'form',\n",
       " 'formaggi',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'from',\n",
       " 'full',\n",
       " 'games',\n",
       " 'garlic',\n",
       " 'gave',\n",
       " 'generous',\n",
       " 'goalkeeper',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gravy',\n",
       " 'great',\n",
       " 'green',\n",
       " 'group',\n",
       " 'gruelling',\n",
       " 'had',\n",
       " 'halep',\n",
       " 'half',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hid',\n",
       " 'highly',\n",
       " 'hip',\n",
       " 'his',\n",
       " 'hodgson',\n",
       " 'hold',\n",
       " 'hope',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'however',\n",
       " 'hubby',\n",
       " 'huge',\n",
       " 'hungry',\n",
       " 'i',\n",
       " 'ice',\n",
       " 'iced',\n",
       " 'if',\n",
       " 'illness',\n",
       " 'important',\n",
       " 'improved',\n",
       " 'in',\n",
       " 'including',\n",
       " 'injury',\n",
       " 'is',\n",
       " 'it',\n",
       " 'italico',\n",
       " 'ivan',\n",
       " 'jelena',\n",
       " 'jonesing',\n",
       " 'jose',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kerber',\n",
       " 'kitchen',\n",
       " 'knock',\n",
       " 'know',\n",
       " 'konta',\n",
       " 'last',\n",
       " 'late',\n",
       " 'laughed',\n",
       " 'lead',\n",
       " 'league',\n",
       " 'led',\n",
       " 'left',\n",
       " 'leicester',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'liverpool',\n",
       " 'located',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'losing',\n",
       " 'losses',\n",
       " 'luka',\n",
       " 'lunchtime',\n",
       " 'madrid',\n",
       " 'major',\n",
       " 'make',\n",
       " 'making',\n",
       " 'manager',\n",
       " 'many',\n",
       " 'match',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'meal',\n",
       " 'miami',\n",
       " 'minutes',\n",
       " 'missed',\n",
       " 'modric',\n",
       " 'moment',\n",
       " 'months',\n",
       " 'montreal',\n",
       " 'montreal.',\n",
       " 'more',\n",
       " 'most',\n",
       " 'much',\n",
       " 'murray',\n",
       " 'my',\n",
       " 'nachos',\n",
       " 'nadal',\n",
       " 'names',\n",
       " 'nederer',\n",
       " 'never',\n",
       " 'new',\n",
       " 'nn7',\n",
       " 'no-quarter-given',\n",
       " 'no1',\n",
       " 'no2',\n",
       " 'no46',\n",
       " 'no83',\n",
       " 'north',\n",
       " 'not',\n",
       " 'odds',\n",
       " 'of',\n",
       " 'off',\n",
       " 'oh-so-familiar',\n",
       " 'omelettes',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'ordered',\n",
       " 'orders',\n",
       " 'ostapenko',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outfit',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'palo',\n",
       " 'pancakes',\n",
       " 'parking',\n",
       " 'pasta',\n",
       " 'patience',\n",
       " 'peak',\n",
       " 'people',\n",
       " 'performances',\n",
       " 'perisic',\n",
       " 'perseyside',\n",
       " 'person',\n",
       " 'pessimistic',\n",
       " 'place',\n",
       " 'places',\n",
       " 'plates',\n",
       " 'played',\n",
       " 'player',\n",
       " 'players',\n",
       " 'pleasantly',\n",
       " 'plus',\n",
       " 'portion',\n",
       " 'portions',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'premier',\n",
       " 'prepare',\n",
       " 'presentation',\n",
       " 'probably',\n",
       " 'promote',\n",
       " 'proved',\n",
       " 'pull',\n",
       " 'pulled',\n",
       " 'quality',\n",
       " 'quarter-final',\n",
       " 'quarter—except',\n",
       " 'quartet',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'rakitic',\n",
       " 'ran',\n",
       " 'ranked',\n",
       " 'ranking',\n",
       " 'rankings',\n",
       " 'ranks',\n",
       " 'reached',\n",
       " 'reaching',\n",
       " 'real',\n",
       " 'really',\n",
       " 'recommendations',\n",
       " 'recommended',\n",
       " 'reds',\n",
       " 'reigning',\n",
       " 'reservations',\n",
       " 'resignation',\n",
       " 'restaurant',\n",
       " 'restaurants',\n",
       " 'results',\n",
       " 'return',\n",
       " 'returning',\n",
       " 'reverse',\n",
       " 'rich',\n",
       " 'roma',\n",
       " 'round',\n",
       " 'row',\n",
       " 'roy',\n",
       " 'run-in',\n",
       " 'russia',\n",
       " 'said',\n",
       " 'salty',\n",
       " 'san',\n",
       " 'sat',\n",
       " 'saturday',\n",
       " 'sauce',\n",
       " 'say',\n",
       " 'scored',\n",
       " 'seal',\n",
       " 'seated',\n",
       " 'seating',\n",
       " 'seeded',\n",
       " 'seeding',\n",
       " 'seem',\n",
       " 'semi-final',\n",
       " 'semis',\n",
       " 'separate',\n",
       " 'serena',\n",
       " 'served',\n",
       " 'server',\n",
       " 'serves',\n",
       " 'service',\n",
       " 'serving',\n",
       " 'she',\n",
       " 'sheets',\n",
       " 'showed',\n",
       " 'side',\n",
       " 'signed',\n",
       " 'signs',\n",
       " 'simona',\n",
       " 'since',\n",
       " 'sisters',\n",
       " 'sliders',\n",
       " 'slides',\n",
       " 'sloane',\n",
       " 'slow',\n",
       " 'slower',\n",
       " 'slump',\n",
       " 'small',\n",
       " 'smash',\n",
       " 'so',\n",
       " 'soft',\n",
       " 'some',\n",
       " 'soon',\n",
       " 'special)',\n",
       " 'spot',\n",
       " 'stage',\n",
       " 'star',\n",
       " 'started',\n",
       " 'starter',\n",
       " 'stephens',\n",
       " 'straight',\n",
       " 'struggled',\n",
       " 'stunning',\n",
       " 'style',\n",
       " 'sub-par',\n",
       " 'succeed',\n",
       " 'summer',\n",
       " 'sunnyvale',\n",
       " 'surged',\n",
       " 'surprised',\n",
       " 'sweet',\n",
       " 'swing',\n",
       " 'table',\n",
       " 'taken',\n",
       " 'taste',\n",
       " 'tasted',\n",
       " 'tea',\n",
       " 'team',\n",
       " 'term',\n",
       " 'tests',\n",
       " 'texture',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thiadal',\n",
       " 'things',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'tie-break',\n",
       " 'time',\n",
       " 'title',\n",
       " 'to',\n",
       " 'toast',\n",
       " 'too',\n",
       " 'took',\n",
       " 'top',\n",
       " 'tough',\n",
       " 'tournament',\n",
       " 'tournaments',\n",
       " 'travel',\n",
       " 'trophy',\n",
       " 'truly',\n",
       " 'turnaround',\n",
       " 'two',\n",
       " 'two-sets',\n",
       " 'undercurrents',\n",
       " 'unless',\n",
       " 'up',\n",
       " 'us',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'victoria',\n",
       " 'victory',\n",
       " 'visit',\n",
       " 'waffle',\n",
       " 'wait',\n",
       " 'waiter',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'was',\n",
       " 'wasnt',\n",
       " 'way',\n",
       " 'we',\n",
       " 'week',\n",
       " 'weekday',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'who',\n",
       " 'why',\n",
       " 'wild',\n",
       " 'will',\n",
       " 'williams',\n",
       " 'wimbledon',\n",
       " 'win',\n",
       " 'winning',\n",
       " 'wins',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonderful',\n",
       " 'world',\n",
       " 'would',\n",
       " 'wozniacki',\n",
       " 'year',\n",
       " 'years',\n",
       " 'year—and',\n",
       " 'york',\n",
       " 'you',\n",
       " '–'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어들에게 일련번호를 붙여주는 작업\n",
    "idx2word = dict(enumerate(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jose\n",
      "years\n"
     ]
    }
   ],
   "source": [
    "print(idx2word[369])\n",
    "print(idx2word[396])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "word2idx = {v:k for k, v in idx2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "369\n"
     ]
    }
   ],
   "source": [
    "print(word2idx[\"years\"])\n",
    "print(word2idx[\"jose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_paragraph(para):\n",
    "    words = para.split()\n",
    "    encoded = []\n",
    "    for w in words :\n",
    "        encoded.append([word2idx[w]])\n",
    "    return encoded\n",
    "# category 를 숫자로 \n",
    "def encoded_category(cate):\n",
    "    if cate == \"food\":\n",
    "        return [1, 0]\n",
    "    else:\n",
    "        return [0, 1]\n",
    "\n",
    "# 문장들의 길이가 다르기 떄문에 길이를 맞춰주어야 한다.     \n",
    "# 가장 긴 문장을 기준으로 길이가 모자란 애들은 크기를 맞추기 위해 의미없는 값을 넣어 주어야 한다. \n",
    "def word_cnt(para):\n",
    "    return len(para.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "      <th>enc_paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[223], [463], [460], [461], [276], [335], [16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[345], [457], [387], [441], [46], [2], [329],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[62], [3], [60], [491], [289], [414], [222], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[45], [365], [458], [11], [353], [311], [281]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[311], [316], [222], [338], [352], [156], [47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category  \\\n",
       "0  dishplace is located in sunnyvale downtown the...     food   \n",
       "1  service can be slower during busy hours but ou...     food   \n",
       "2  portions are huge both french toast and their ...     food   \n",
       "3  we started with apps going the chicken and waf...     food   \n",
       "4  the biscuits and gravy was too salty two peopl...     food   \n",
       "\n",
       "                                       enc_paragraph  \n",
       "0  [[223], [463], [460], [461], [276], [335], [16...  \n",
       "1  [[345], [457], [387], [441], [46], [2], [329],...  \n",
       "2  [[62], [3], [60], [491], [289], [414], [222], ...  \n",
       "3  [[45], [365], [458], [11], [353], [311], [281]...  \n",
       "4  [[311], [316], [222], [338], [352], [156], [47...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"enc_paragraph\"] = df.paragraph.apply(encoded_paragraph)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "      <th>enc_paragraph</th>\n",
       "      <th>enc_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[223], [463], [460], [461], [276], [335], [16...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[345], [457], [387], [441], [46], [2], [329],...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[62], [3], [60], [491], [289], [414], [222], ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[45], [365], [458], [11], [353], [311], [281]...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[311], [316], [222], [338], [352], [156], [47...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category  \\\n",
       "0  dishplace is located in sunnyvale downtown the...     food   \n",
       "1  service can be slower during busy hours but ou...     food   \n",
       "2  portions are huge both french toast and their ...     food   \n",
       "3  we started with apps going the chicken and waf...     food   \n",
       "4  the biscuits and gravy was too salty two peopl...     food   \n",
       "\n",
       "                                       enc_paragraph enc_category  \n",
       "0  [[223], [463], [460], [461], [276], [335], [16...       [1, 0]  \n",
       "1  [[345], [457], [387], [441], [46], [2], [329],...       [1, 0]  \n",
       "2  [[62], [3], [60], [491], [289], [414], [222], ...       [1, 0]  \n",
       "3  [[45], [365], [458], [11], [353], [311], [281]...       [1, 0]  \n",
       "4  [[311], [316], [222], [338], [352], [156], [47...       [1, 0]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"enc_category\"] = df.category.apply(encoded_category)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "      <th>enc_paragraph</th>\n",
       "      <th>enc_category</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[223], [463], [460], [461], [276], [335], [16...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[345], [457], [387], [441], [46], [2], [329],...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[62], [3], [60], [491], [289], [414], [222], ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[45], [365], [458], [11], [353], [311], [281]...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "      <td>[[311], [316], [222], [338], [352], [156], [47...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category  \\\n",
       "0  dishplace is located in sunnyvale downtown the...     food   \n",
       "1  service can be slower during busy hours but ou...     food   \n",
       "2  portions are huge both french toast and their ...     food   \n",
       "3  we started with apps going the chicken and waf...     food   \n",
       "4  the biscuits and gravy was too salty two peopl...     food   \n",
       "\n",
       "                                       enc_paragraph enc_category  seq_length  \n",
       "0  [[223], [463], [460], [461], [276], [335], [16...       [1, 0]          53  \n",
       "1  [[345], [457], [387], [441], [46], [2], [329],...       [1, 0]          19  \n",
       "2  [[62], [3], [60], [491], [289], [414], [222], ...       [1, 0]          42  \n",
       "3  [[45], [365], [458], [11], [353], [311], [281]...       [1, 0]          43  \n",
       "4  [[311], [316], [222], [338], [352], [156], [47...       [1, 0]          82  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"seq_length\"] = df.paragraph.apply(word_cnt)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "# 문장의 최대 길이 알아내기\n",
    "# df.sort_values(by=[\"seq_length\"], axis=0, ascending = False)\n",
    "max_word_cnt = 0\n",
    "\n",
    "for row in df[\"paragraph\"]:\n",
    "    if len(row.split()) > max_word_cnt : \n",
    "        max_word_cnt = len(row.split())\n",
    "\n",
    "print(max_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 길이가 91개가 안될 경우 : -1 로 채우기 \n",
    "def sequence_padding(enc_para):\n",
    "    seq_len = len(enc_para)\n",
    "    for i in range(seq_len, max_word_cnt):\n",
    "        enc_para.append([-1])\n",
    "    return enc_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"enc_paragraph\"] = df.enc_paragraph.apply(sequence_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[223], [463], [460], [461], [276], [335], [165], [463], [64], [462], [311], [239], [471], [508], [457], [387], [438], [203], [364], [46], [53], [101], [329], [402], [490], [222], [140], [43], [203], [142], [454], [122], [427], [37], [31], [433], [524], [380], [125], [2], [512], [140], [501], [291], [213], [395], [82], [298], [451], [311], [262], [203], [480], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1]]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"enc_paragraph\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값들을 배열로 변환 \n",
    "enc_paragraph = np.array(df.enc_paragraph.tolist())\n",
    "enc_category = np.array(df.enc_category.tolist())\n",
    "seq_length = np.array(df.seq_length.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 19, 42, 43, 82, 24, 50, 43, 49, 82, 65, 88, 91, 71, 70, 30, 35,\n",
       "       30, 63, 46])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 91, 1) (20, 2)\n"
     ]
    }
   ],
   "source": [
    "train_X = enc_paragraph\n",
    "train_y = enc_category\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:0.8848035, acc:0.5\n",
      "epoch:50, cost:0.40894026, acc:0.8\n",
      "epoch:100, cost:0.0679994, acc:1.0\n",
      "epoch:150, cost:0.003567428, acc:1.0\n",
      "epoch:200, cost:0.0014474727, acc:1.0\n",
      "epoch:250, cost:0.0008162061, acc:1.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# parameter \n",
    "lr = 0.001\n",
    "total_epochs = 300\n",
    "\n",
    "# mnay to one \n",
    "X = tf.placeholder(tf.float32, shape = [None, max_word_cnt, 1]) # 입력갯수는 91개 = max_word_cnt \n",
    "y = tf.placeholder(tf.int32, shape = [None, 2]) # food, sport 둘중하나이므로 2 \n",
    "\n",
    "embeded = tf.layers.dense(X, 5)  # 학습과정을 좀 더 deep 하게 가져갈 때에도 dense를 통해 간편하게 만들 수 있다.\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=64)\n",
    "outputs ,state = tf.nn.dynamic_rnn(cell=cell, inputs=embeded, dtype = tf.float32, sequence_length= seq_length) \n",
    "\n",
    "# -1은 길이를 맞춰주기 위해 넣은 것이기 때문에 학습하면 안된다 \n",
    "# 유효한 데이터만 가지고 학습할 수 있도록 해주는 것이 dynamic_rnn\n",
    "# 융통성 있게 학습할 수 있게 해주는 게 dynamic_rnn\n",
    "# 반대되는 것이 static_rnn으로 이는 고정된 길이만 학습할 수 있다. \n",
    "# 입력되는 갯수가 다르다는 것을 알려주기 위해서 sequence_length 인자를 사용\n",
    "\n",
    "# state를 가져온 이유는 이중분류이기 때문에 outputs값은 사용하지않고 최종 히든스테이트를 통해 얻은 이중분류 값을 가져오게된다.\n",
    "# state는 이미 평면화 작업이 되어있는 것이기 때문에 따로 평면화 작업을 할 필요는 없다. \n",
    "first_layer = tf.layers.dense(state.h, 32) \n",
    "logit = tf.layers.dense(first_layer, 2) #logit / 마지막 출력갯수는 맞춰주어야 한다.\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels= y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "# print(X)\n",
    "# print(embeded)\n",
    "# print(state)\n",
    "# print(first_layer)\n",
    "# print(logit)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(total_epochs):\n",
    "        _, c = sess.run([train,cost], feed_dict={X:train_X, y:train_y})\n",
    "        if epoch % 50 == 0:\n",
    "            pred = tf.nn.softmax(logit)\n",
    "            correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "            cur_acc = accuracy.eval({X:train_X, y:train_y})\n",
    "            print(\"epoch:\" + str(epoch) + \", cost:\"+ str(c) + \", acc:\" + str(cur_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data...\n",
      "Iter= 1000, Average Loss= 4.334711, Average Accuracy= 4.80%\n",
      "['spoke', '.', 'then'] - [the] vs [an]\n",
      "Iter= 2000, Average Loss= 2.850103, Average Accuracy= 20.50%\n",
      "['well', ',', 'but'] - [who] vs [,]\n",
      "Iter= 3000, Average Loss= 2.593837, Average Accuracy= 30.50%\n",
      "['was', 'in', 'the'] - [neighbourhood] vs [neighbourhood]\n",
      "Iter= 4000, Average Loss= 2.097472, Average Accuracy= 45.70%\n",
      "['when', 'she', 'was'] - [about] vs [about]\n",
      "Iter= 5000, Average Loss= 1.978992, Average Accuracy= 50.10%\n",
      "['be', 'procured', ','] - [and] vs [then]\n",
      "Iter= 6000, Average Loss= 1.758271, Average Accuracy= 58.70%\n",
      "['easily', 'escape', 'from'] - [her] vs [her]\n",
      "Iter= 7000, Average Loss= 1.410386, Average Accuracy= 62.30%\n",
      "['now', ',', 'if'] - [we] vs [,]\n",
      "Iter= 8000, Average Loss= 1.311625, Average Accuracy= 64.60%\n",
      "['that', 'our', 'chief'] - [danger] vs [the]\n",
      "Iter= 9000, Average Loss= 1.167619, Average Accuracy= 68.80%\n",
      "['thought', 'would', 'meet'] - [the] vs [in]\n",
      "Iter= 10000, Average Loss= 1.073276, Average Accuracy= 71.20%\n",
      "['said', 'he', 'had'] - [a] vs [met]\n",
      "Iter= 11000, Average Loss= 0.915644, Average Accuracy= 77.00%\n",
      "['at', 'last', 'a'] - [young] vs [young]\n",
      "Iter= 12000, Average Loss= 0.790304, Average Accuracy= 80.00%\n",
      "['their', 'common', 'enemy'] - [,] vs [,]\n",
      "Iter= 13000, Average Loss= 0.970886, Average Accuracy= 75.80%\n",
      "['what', 'measures', 'they'] - [could] vs [they]\n",
      "Iter= 14000, Average Loss= 0.731844, Average Accuracy= 80.70%\n",
      "['it', 'is', 'easy'] - [to] vs [to]\n",
      "Iter= 15000, Average Loss= 0.808598, Average Accuracy= 79.00%\n",
      "['very', 'well', ','] - [but] vs [but]\n",
      "Iter= 16000, Average Loss= 0.811357, Average Accuracy= 79.00%\n",
      "['in', 'the', 'neighbourhood'] - [.] vs [and]\n",
      "Iter= 17000, Average Loss= 0.731732, Average Accuracy= 81.50%\n",
      "['neck', 'of', 'the'] - [cat] vs [cat]\n",
      "Iter= 18000, Average Loss= 0.654178, Average Accuracy= 83.90%\n",
      "['i', 'venture', ','] - [therefore] vs [and]\n",
      "Iter= 19000, Average Loss= 0.731249, Average Accuracy= 82.90%\n",
      "['approach', ',', 'we'] - [could] vs [could]\n",
      "Iter= 20000, Average Loss= 0.673087, Average Accuracy= 81.90%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 21000, Average Loss= 0.487166, Average Accuracy= 86.00%\n",
      "['last', 'a', 'young'] - [mouse] vs [to]\n",
      "Iter= 22000, Average Loss= 0.785584, Average Accuracy= 81.40%\n",
      "[',', 'the', 'cat'] - [.] vs [.]\n",
      "Iter= 23000, Average Loss= 0.707936, Average Accuracy= 82.40%\n",
      "['consider', 'what', 'measures'] - [they] vs [enemy]\n",
      "Iter= 24000, Average Loss= 0.551384, Average Accuracy= 86.40%\n",
      "['is', 'easy', 'to'] - [propose] vs [propose]\n",
      "Iter= 25000, Average Loss= 0.578256, Average Accuracy= 87.00%\n",
      "['said', 'it', 'is'] - [easy] vs [easy]\n",
      "Iter= 26000, Average Loss= 0.586526, Average Accuracy= 86.40%\n",
      "['the', 'mice', 'looked'] - [at] vs [us]\n",
      "Iter= 27000, Average Loss= 0.647159, Average Accuracy= 83.80%\n",
      "['well', ',', 'but'] - [who] vs [who]\n",
      "Iter= 28000, Average Loss= 0.598685, Average Accuracy= 86.10%\n",
      "['the', 'neighbourhood', '.'] - [this] vs [this]\n",
      "Iter= 29000, Average Loss= 0.534332, Average Accuracy= 86.90%\n",
      "['always', 'know', 'when'] - [she] vs [when]\n",
      "Iter= 30000, Average Loss= 0.559078, Average Accuracy= 86.60%\n",
      "['and', 'attached', 'by'] - [a] vs [a]\n",
      "Iter= 31000, Average Loss= 0.600691, Average Accuracy= 86.50%\n",
      "[',', 'to', 'propose'] - [that] vs [that]\n",
      "Iter= 32000, Average Loss= 0.581404, Average Accuracy= 85.30%\n",
      "['could', 'receive', 'some'] - [signal] vs [signal]\n",
      "Iter= 33000, Average Loss= 0.555069, Average Accuracy= 86.60%\n",
      "['in', 'which', 'the'] - [enemy] vs [enemy]\n",
      "Iter= 34000, Average Loss= 0.532264, Average Accuracy= 87.50%\n",
      "['sly', 'and', 'treacherous'] - [manner] vs [manner]\n",
      "Iter= 35000, Average Loss= 0.645133, Average Accuracy= 86.20%\n",
      "['which', 'he', 'thought'] - [would] vs [would]\n",
      "Iter= 36000, Average Loss= 0.604040, Average Accuracy= 85.80%\n",
      "['young', 'mouse', 'got'] - [up] vs [up]\n",
      "Iter= 37000, Average Loss= 0.589938, Average Accuracy= 86.00%\n",
      "['common', 'enemy', ','] - [the] vs [the]\n",
      "Iter= 38000, Average Loss= 0.448180, Average Accuracy= 88.50%\n",
      "['it', 'is', 'easy'] - [to] vs [,]\n",
      "Iter= 39000, Average Loss= 0.368962, Average Accuracy= 91.80%\n",
      "['is', 'all', 'very'] - [well] vs [well]\n",
      "Iter= 40000, Average Loss= 0.435391, Average Accuracy= 90.30%\n",
      "['while', 'she', 'was'] - [in] vs [about]\n",
      "Iter= 41000, Average Loss= 0.377379, Average Accuracy= 90.30%\n",
      "['by', 'this', 'means'] - [we] vs [we]\n",
      "Iter= 42000, Average Loss= 0.450131, Average Accuracy= 88.70%\n",
      "['bell', 'be', 'procured'] - [,] vs [,]\n",
      "Iter= 43000, Average Loss= 0.525168, Average Accuracy= 86.50%\n",
      "['small', 'bell', 'be'] - [procured] vs [procured]\n",
      "Iter= 44000, Average Loss= 0.426196, Average Accuracy= 89.00%\n",
      "['receive', 'some', 'signal'] - [of] vs [of]\n",
      "Iter= 45000, Average Loss= 0.404211, Average Accuracy= 89.80%\n",
      "['manner', 'in', 'which'] - [the] vs [the]\n",
      "Iter= 46000, Average Loss= 0.477008, Average Accuracy= 89.00%\n",
      "['case', '.', 'you'] - [will] vs [will]\n",
      "Iter= 47000, Average Loss= 0.411882, Average Accuracy= 90.00%\n",
      "['but', 'at', 'last'] - [a] vs [a]\n",
      "Iter= 48000, Average Loss= 0.483462, Average Accuracy= 89.70%\n",
      "['some', 'said', 'this'] - [,] vs [,]\n",
      "Iter= 49000, Average Loss= 0.483778, Average Accuracy= 88.60%\n",
      "['cat', '.', 'some'] - [said] vs [said]\n",
      "Iter= 50000, Average Loss= 0.397446, Average Accuracy= 91.00%\n",
      "['council', 'to', 'consider'] - [what] vs [what]\n",
      "Optimization Finished!\n",
      "Elapsed time:  12.845741868019104 min\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=log_dir/tmp/tensorflow/rnn_words\n",
      "Point your web browser to: http://localhost:6006/\n",
      "3 words: had a general\n",
      "had a general council to consider what measures they they they they they they they they they they they they they they they they they they they they they they they they they they they\n",
      "3 words: had a general\n",
      "had a general council to consider what measures they they they they they they they they they they they they they they they they they they they they they they they they they they they\n",
      "3 words: point your web\n",
      "Word not in dictionary\n",
      "3 words: had a general\n",
      "had a general council to consider what measures they they they they they they they they they they they they they they they they they they they they they they they they they they they\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-6e909ebd4034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s words: \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# https://insightcampus.co.kr/insightcommunity/?mod=document&uid=12936\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "start_time = time.time()\n",
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec<(60*60):\n",
    "        return str(sec/60) + \" min\"\n",
    "    else:\n",
    "        return str(sec/(60*60)) + \" hr\"\n",
    "\n",
    "\n",
    "# Target log path\n",
    "logs_path = 'log_dir/tmp/tensorflow/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file = 'data/belling_the_cat.txt'\n",
    "\n",
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [word for i in range(len(content)) for word in content[i].split()]\n",
    "    content = np.array(content)\n",
    "    \n",
    "    return content\n",
    "\n",
    "training_data = read_data(training_file)\n",
    "print(\"Loaded training data...\")\n",
    "\n",
    "def build_dataset(words): # 단어하고 숫자를 하나의 딕트형식으로 묶은 것\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary \n",
    "        # 키 : 값          값 : 키\n",
    "dictionary, reverse_dictionary = build_dataset(training_data)\n",
    "vocab_size = len(dictionary)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "display_step = 1000\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0,n_input+1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data)-end_offset):\n",
    "            offset = random.randint(0, n_input+1)\n",
    "\n",
    "        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = training_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input+1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
